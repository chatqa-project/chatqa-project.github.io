<html>
  <head>
    <meta charvctk_set="UTF-8">
    <title>Introducing ChatQA-1.5</title>
    <style type="text/css">

      /* css for table */
      .tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
      .tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
        font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
      .tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
        font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
      .tg .tg-iw6l{border-color:inherit;font-family:"Trebuchet MS", Helvetica, sans-serif !important;text-align:left;vertical-align:top}
      .tg .tg-2dy9{border-color:inherit;font-family:"Trebuchet MS", Helvetica, sans-serif !important;text-align:center;vertical-align:top}
      
      /* css for text container */
      .container {
        margin: 0 auto; /* Center the container horizontally */
        max-width: 600px; /* Set the maximum width of the container */
        text-align: center; /* Center the text within the container */
        padding: 0 20px; /* Optional: Add padding to the container */
      }
    </style>
  </head>
  <div class="container">

    <h2>Introducing ChatQA-1.5: Outperforming GPT-4 at Conversational Question Answering</h2>
    <h3><a href="https://arxiv.org/abs/2401.10225">Link to Paper (arXiv)</a> &ensp; <a href="">Link to Models</a> &ensp; <a href="">Link to Data</a> </h3>
    <p>
    Today, we release ChatQA-1.5-8b and ChatQA-1.5-70b models, which excels at RAG-based conversational question answering (QA). ChatQA-1.5 is built using the recipe from <a href="https://arxiv.org/abs/2401.10225">ChatQA (1.0)</a> on top of Llama-3 foundation model. Additionally, we incorporate more conversational QA data to enhance its tabular and arithmatic calculation capability.
    </p>

    <h3>ConvRAG Bench</h3>
    We introduce ConvRAG Bench: a benchmark for retrieval/context-augmented conversational QA evaluation. ConvRAG Bench consisting of 10 datasets: <a href="https://arxiv.org/abs/2011.06623">Doc2Dial</a>, QuAC, QReCC, TopioCQA, INSCIT, CoQA, HybriDialogue, DoQA, SQA, ConvFinQA, which covers both long and short text-based documents, tabular reasoning and arithmatic calculations.

    <!-- tables for the ConvRAG Bench -->
    <table class="tg">
      <thead>
        <tr>
          <th class="tg-iw6l"></th>
          <th class="tg-2dy9">ChatQA-1.0-7B</th>
          <th class="tg-2dy9">Command-R-Plus</th>
          <th class="tg-2dy9">Llama-3-instruct-70b</th>
          <th class="tg-2dy9">GPT-4-0613</th>
          <th class="tg-2dy9">ChatQA-1.0-70B</th>
          <th class="tg-2dy9">ChatQA-1.5-8B</th>
          <th class="tg-2dy9">ChatQA-1.5-70B</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td class="tg-iw6l">doc2dial</td>
          <td class="tg-2dy9">37.88</td>
          <td class="tg-2dy9">33.51</td>
          <td class="tg-2dy9">37.88</td>
          <td class="tg-2dy9">34.16</td>
          <td class="tg-2dy9">38.9</td>
          <td class="tg-2dy9">39.33</td>
          <td class="tg-2dy9">41.26</td>
        </tr>
        <tr>
          <td class="tg-iw6l">quac</td>
          <td class="tg-2dy9">29.69</td>
          <td class="tg-2dy9">34.16</td>
          <td class="tg-2dy9">36.96</td>
          <td class="tg-2dy9">40.29</td>
          <td class="tg-2dy9">41.82</td>
          <td class="tg-2dy9">39.73</td>
          <td class="tg-2dy9">38.82</td>
        </tr>
        <tr>
          <td class="tg-iw6l">qrecc</td>
          <td class="tg-2dy9">46.97</td>
          <td class="tg-2dy9">49.77</td>
          <td class="tg-2dy9">51.34</td>
          <td class="tg-2dy9">52.01</td>
          <td class="tg-2dy9">48.05</td>
          <td class="tg-2dy9">49.03</td>
          <td class="tg-2dy9">51.40</td>
        </tr>
        <tr>
          <td class="tg-iw6l">coqa</td>
          <td class="tg-2dy9">76.61</td>
          <td class="tg-2dy9">69.71</td>
          <td class="tg-2dy9">76.98</td>
          <td class="tg-2dy9">77.42</td>
          <td class="tg-2dy9">78.57</td>
          <td class="tg-2dy9">76.46</td>
          <td class="tg-2dy9">78.44</td>
        </tr>
        <tr>
          <td class="tg-iw6l">doqa</td>
          <td class="tg-2dy9">41.57</td>
          <td class="tg-2dy9">40.67</td>
          <td class="tg-2dy9">41.24</td>
          <td class="tg-2dy9">43.39</td>
          <td class="tg-2dy9">51.94</td>
          <td class="tg-2dy9">49.60</td>
          <td class="tg-2dy9">50.67</td>
        </tr>
        <tr>
          <td class="tg-iw6l">convfinqa</td>
          <td class="tg-2dy9">51.61</td>
          <td class="tg-2dy9">71.21</td>
          <td class="tg-2dy9">76.60</td>
          <td class="tg-2dy9">81.28</td>
          <td class="tg-2dy9">73.69</td>
          <td class="tg-2dy9">78.46</td>
          <td class="tg-2dy9">81.88</td>
        </tr>
        <tr>
          <td class="tg-iw6l">sqa</td>
          <td class="tg-2dy9">61.87</td>
          <td class="tg-2dy9">74.07</td>
          <td class="tg-2dy9">69.61</td>
          <td class="tg-2dy9">79.21</td>
          <td class="tg-2dy9">69.14</td>
          <td class="tg-2dy9">73.28</td>
          <td class="tg-2dy9">83.82</td>
        </tr>
        <tr>
          <td class="tg-iw6l">topiocqa</td>
          <td class="tg-2dy9">45.45</td>
          <td class="tg-2dy9">53.77</td>
          <td class="tg-2dy9">49.72</td>
          <td class="tg-2dy9">45.09</td>
          <td class="tg-2dy9">50.98</td>
          <td class="tg-2dy9">49.96</td>
          <td class="tg-2dy9">55.63</td>
        </tr>
        <tr>
          <td class="tg-iw6l">hybridial<span style="font-style:italic">*</span></td>
          <td class="tg-2dy9">54.51</td>
          <td class="tg-2dy9">46.70</td>
          <td class="tg-2dy9">48.59</td>
          <td class="tg-2dy9">49.81</td>
          <td class="tg-2dy9">56.44</td>
          <td class="tg-2dy9">65.76</td>
          <td class="tg-2dy9">68.27</td>
        </tr>
        <tr>
          <td class="tg-iw6l">inscit</td>
          <td class="tg-2dy9">30.96</td>
          <td class="tg-2dy9">35.76</td>
          <td class="tg-2dy9">36.23</td>
          <td class="tg-2dy9">36.34</td>
          <td class="tg-2dy9">31.90</td>
          <td class="tg-2dy9">30.10</td>
          <td class="tg-2dy9">32.31</td>
        </tr>
        <tr>
          <td class="tg-iw6l">average (all)</td>
          <td class="tg-2dy9">47.71</td>
          <td class="tg-2dy9">50.93</td>
          <td class="tg-2dy9">52.52</td>
          <td class="tg-2dy9">53.90</td>
          <td class="tg-2dy9">54.14</td>
          <td class="tg-2dy9">55.17</td>
          <td class="tg-2dy9">58.25</td>
        </tr>
        <tr>
          <td class="tg-iw6l">average (except hybridial)</td>
          <td class="tg-2dy9">46.96</td>
          <td class="tg-2dy9">51.40</td>
          <td class="tg-2dy9">52.95</td>
          <td class="tg-2dy9">54.35</td>
          <td class="tg-2dy9">53.89</td>
          <td class="tg-2dy9">53.99</td>
          <td class="tg-2dy9">57.14</td>
        </tr>
      </tbody>
      </table>

    ConvRAG Bench also includes evaluations for unanswerable scenarios
    
    <h3>Training Datasets</h3>
    We release <a href="">training datasets</a> which include our conversational QA dataset and single-turn QA datasets.

    <h3>Conversational QA Retriever</h3>
    We release conversational QA retriever

    <h3>License</h3>

    <h3>Citation</h3>


  </div>
  

</html>


